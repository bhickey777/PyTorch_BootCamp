import torch
from torch import nn ## pytorch neural networks
from torch.utils.data import Dataset, DataLoader

import numpy as np
import matplotlib.pyplot as plt
import time

from pathlib import Path

RANDOM_SEED = 42
torch.manual_seed(RANDOM_SEED)

epoch_count = []
loss_values = []
test_loss_values = []

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"using device {device}")

weight = 0.7 # a is the intercept or the value of y when x is zero
bias = 0.3 # b is the slope of the line

# model will estimate the values of x and y.
start = 0
end = 1
step = 0.02

# for complex datasets can use torch.utils.data.Dataset and torch.utils.data.DataLoader
# rather then generating random numbers

X = torch.arange(start, end, step).unsqueeze(dim = 1)
y = weight * X + bias


# 2. Split the data into training (60-80% of data) and test sets (10-20%)
train_split = int(0.8 * len(X))
X_train, y_train = X[:train_split], y[:train_split]
X_test, y_test = X[train_split:],y[train_split:]


#3. Build the model for predicting the linear regression values
class LinearRegressionModel(nn.Module):

    def __init__(self):
        super().__init__()

        # can use random or torch.optim to optimize the data
        self.weights = nn.Parameter(torch.randn(1,
                                                requires_grad=True,
                                                dtype=torch.float))
        self.bias = nn.Parameter(torch.randn(1,
                                             requires_grad=True,
                                             dtype=torch.float))

    # use the formula to provide the computation of the model
    # ideally model will run random weights and bias and come close to value
    # as prescribed by the linear regression formula
    # forward is invoked by Module for each cell defined by the parameters

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.weights * x + self.bias
    
#make the training and test sets visual
def plot_predictions(train_data=X_train,
                     train_labels=y_train,
                     test_data=X_test,
                     test_labels=y_test,
                     predictions = None):
    
    # plot training data, test data, and compares predictions
    #matplotlib scatter graph
    plt.figure(figsize=(10, 7))

    # plot the training data in blue
    plt.scatter(train_data, train_labels, c="b", s=4, label = "Training Data") # color of blue

    #plot the test data in green
    plt.scatter(test_data, test_labels, c="g", s=4, label="Test Data")

    if predictions is not None:
        #plot the predications
        plt.scatter(test_data, predictions, c="y", s=4, label="Predications")

    plt.legend(prop={"size": 14})
    return plt

def showPlot(file_name, plt):

    plt.savefig(file_name) 
    plt.show()

#create a instance of your model
model_0 = LinearRegressionModel()
list_parms = list(model_0.parameters()) #this is the generator
parm_names = model_0.state_dict()

#4. How to train the model - move from some unknown to some known parameters
#   You can use a loss function or criterion to measure the effectiveness of a model 

#   Optimizer - takes into account the loss of a model and adjusts the models weights and bias 
#   to improve the loss function. 

#   Need a training and a testing loop in order to achieve this 

#Setup a loss function
loss_fn = nn.L1Loss() #how bad is the model performing

#Setup an optimizer (ways to adjust the parameters)
optimizer = torch.optim.SGD(
    params = model_0.parameters(), 
    lr=0.01, #learning rate is a hyperparameter (higher learning more adjustment)
    momentum=0.9) #
    
    #   Build the training loop using PyTorch
    #   Training loop needs to go thru the data and make a forward pass thru the model
    #   Calculate the loss then optimize moving backward thru the model to pick up the
    #   gradients trying to improve the loss

# an epoch is one loop thru the data
epochs = 200
for epoch in range(epochs):       
    #Set the model to training mode
    model_0.train()       
    #1. Forward pass
    y_preds = model_0(X_train)
    print(y_preds)

    #2. Calculate the loss
    loss = loss_fn(y_preds, y_train)
    print(f"Loss: {loss} epoch: {epoch}")

    #3. Optimize with a zero gradient (clears out the previous context/gradients)
    optimizer.zero_grad()

    #4. Perform back propagation on the loss with respect to parameters of the model
    loss.backward()

    #5. Step the optimizer(perform gradient descent)
    optimizer.step()

    #Turns model out of training mode and allows model to be evaluated / tested
    model_0.eval()

    #Print out model state dict
    # print(model_0.state_dict())

    #Now with the model having been trained lets check with some test data
    with torch.inference_mode(): # turns off gradient tracking 

        # 1. do a forward pass thru the model
        y_preds_new = model_0(X_test) 

        #  2. Calculate the loss on the test data 
        test_loss = loss_fn(y_preds_new, y_test)

    if epoch % 10 == 0:
        epoch_count.append(epoch)
        loss_values.append(loss)
        test_loss_values.append(test_loss)

        print(f"Epoch: {epoch} | Loss: {loss} | Test Loss: {test_loss}")

#plt = plot_predictions(predictions=y_preds_new);
#showPlot('post testing model.png', plt)

# need to convert tensors to numpy arrays
np_loss_values = np.array(torch.tensor(loss_values).numpy())
np_test_loss_values = np.array(torch.tensor(test_loss_values).numpy())

plt.plot(epoch_count, np_loss_values, label="Loss Values")
plt.plot(epoch_count, np_test_loss_values, label="Test Loss")
plt.title("Training and test loss curves")
plt.ylabel("Loss")
plt.xlabel("Epochs")

showPlot("train_test_loss.png", plt)

# Save the model to be ran later or shared
# torch.save() torch.load() [serialize and deserialize python objects]
# torch.nn.Module.load_state_dict() [holds the state of the model]
MODEL_PATH = Path("models")
MODEL_PATH.mkdir(parents=True, exist_ok=True)
MODEL_NAME = "01_s3_062325.pth"
MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME

print(f"Saving model to : {MODEL_SAVE_PATH}")
torch.save(model_0.state_dict(), MODEL_SAVE_PATH)

print(f"Loading model from : {MODEL_SAVE_PATH}")
_modelState = torch.load(MODEL_SAVE_PATH)
print(_modelState)

loaded_model_0 = LinearRegressionModel()
loaded_model_0.load_state_dict(_modelState)
print(loaded_model_0.state_dict())

#Make some predictions to ensure loaded model works
loaded_model_0.eval()
with torch.inference_mode():
    loaded_model_preds = loaded_model_0(X_test)

model_0.eval()
with torch.inference_mode():
    y_preds = model_0(X_test)

#compare loaded predictions model with existing model
print(y_preds == loaded_model_preds)
